{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from getpass import getpass\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec, Index\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load the API keys from .env\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_JSON_FILE = 'arxiv_papers.json'\n",
    "DATA_FOLDER = '../data'\n",
    "PDF_FOLDER = '../data/pdfs/'\n",
    "OUTPUT_JSON_FILEPATH = os.path.join(DATA_FOLDER, OUTPUT_JSON_FILE)\n",
    "DF_PDF_CSV_FILE = \"arxiv_papers_with_pdfs.csv\"\n",
    "DF_PDF_CSV_FILEPATH = os.path.join(PDF_FOLDER, DF_PDF_CSV_FILE)\n",
    "\n",
    "\n",
    "CHUNK_SIZE = 512\n",
    "CHUNK_OVERLAP = 64\n",
    "\n",
    "INDEX_NAME = 'langgraph-research-agent'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"BAAI/bge-small-en\"\n",
    "EMBEDDING_DIMS = 384\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting and Chunking of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_chunk_pdf(pdf_file_name: str, \n",
    "                       saved_dir: str=PDF_FOLDER,\n",
    "                       chunk_size: int=CHUNK_SIZE, \n",
    "                       chunk_overlap: int=CHUNK_OVERLAP) -> list[str]:\n",
    "    \"\"\"\n",
    "    Loads a PDF file into chunks and returns a list of chunks.\n",
    "    Args:\n",
    "        pdf_file_name (str): The name of the PDF file.\n",
    "        saved_dir (str): The directory where the PDF file is saved. Default is PDF_FOLDER.\n",
    "        chunk_size (int): The size of each chunk in bytes. Default is CHUNK_SIZE.\n",
    "        chunk_overlap (int): The overlap between chunks in bytes. Default is CHUNK_OVERLAP.\n",
    "    Returns:\n",
    "        List[str]: A list of chunks from the PDF file.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'Loading and splitting into chunks: {pdf_file_name}')\n",
    "    # name = remove_dot_from_filename(pdf_file_name)\n",
    "    # print(name)\n",
    "    \n",
    "    pdf_file_path = os.path.join(saved_dir, pdf_file_name)\n",
    "\n",
    "    # Load the PDF file into a DocumentLoader object\n",
    "    loader = PyPDFLoader(pdf_file_path)\n",
    "    data = loader.load()\n",
    "\n",
    "    # Split the text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, \n",
    "                                                   chunk_overlap=chunk_overlap)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_chunks_to_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds chunks to the DataFrame, including their IDs and metadata.\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the paper details.\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated DataFrame with added chunk information.\n",
    "    \"\"\"\n",
    "\n",
    "    expanded_rows = []  # List to store expanded rows with chunk information\n",
    "\n",
    "    # Loop through each row in the DataFrame\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            chunks = load_and_chunk_pdf(row['pdf_file_name'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {row['pdf_file_name']}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            pre_chunk_id = i-1 if i > 0 else ''  # Preceding chunk ID\n",
    "            post_chunk_id = i+1 if i < len(chunks) - 1 else ''  # Following chunk ID\n",
    "\n",
    "            expanded_rows.append({\n",
    "                'id': f\"{row['arxiv_id']}#{i}\",  # Unique chunk identifier\n",
    "                'title': row['title'],\n",
    "                'summary': row['summary'],\n",
    "                'authors': row['authors'],\n",
    "                'arxiv_id': row['arxiv_id'],\n",
    "                'url': row['url'],\n",
    "                'chunk': chunk.page_content,  # Text content of the chunk\n",
    "                'pre_chunk_id': '' if i == 0 else f\"{row['arxiv_id']}#{pre_chunk_id}\",  # Previous chunk ID\n",
    "                'post_chunk_id': '' if i == len(chunks) - 1 else f\"{row['arxiv_id']}#{post_chunk_id}\"  # Next chunk ID\n",
    "            })\n",
    "    # Return a new expanded DataFrame\n",
    "    return pd.DataFrame(expanded_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_link</th>\n",
       "      <th>published</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>pdf_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cedille: A large autoregressive French languag...</td>\n",
       "      <td>Scaling up the size and training of autoregres...</td>\n",
       "      <td>['Martin Müller', 'Florian Laurent']</td>\n",
       "      <td>http://arxiv.org/abs/2202.03371v1</td>\n",
       "      <td>http://arxiv.org/pdf/2202.03371v1</td>\n",
       "      <td>2022-02-07T17:40:43Z</td>\n",
       "      <td>2202.03371v1</td>\n",
       "      <td>2202.03371v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Precis of Language Models are not Models of ...</td>\n",
       "      <td>Natural Language Processing is one of the lead...</td>\n",
       "      <td>['Csaba Veres']</td>\n",
       "      <td>http://arxiv.org/abs/2205.07634v1</td>\n",
       "      <td>http://arxiv.org/pdf/2205.07634v1</td>\n",
       "      <td>2022-05-16T12:50:58Z</td>\n",
       "      <td>2205.07634v1</td>\n",
       "      <td>2205.07634v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Integrating AI Planning with Natural Language ...</td>\n",
       "      <td>Natural language processing (NLP) aims at inve...</td>\n",
       "      <td>['Kebing Jin', 'Hankz Hankui Zhuo']</td>\n",
       "      <td>http://arxiv.org/abs/2202.07138v2</td>\n",
       "      <td>http://arxiv.org/pdf/2202.07138v2</td>\n",
       "      <td>2022-02-15T02:19:09Z</td>\n",
       "      <td>2202.07138v2</td>\n",
       "      <td>2202.07138v2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multilingual Text Classification for Dravidian...</td>\n",
       "      <td>As the fourth largest language family in the w...</td>\n",
       "      <td>['Xiaotian Lin', 'Nankai Lin', 'Kanoksak Watta...</td>\n",
       "      <td>http://arxiv.org/abs/2112.01705v1</td>\n",
       "      <td>http://arxiv.org/pdf/2112.01705v1</td>\n",
       "      <td>2021-12-03T04:26:49Z</td>\n",
       "      <td>2112.01705v1</td>\n",
       "      <td>2112.01705v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PersianLLaMA: Towards Building First Persian L...</td>\n",
       "      <td>Despite the widespread use of the Persian lang...</td>\n",
       "      <td>['Mohammad Amin Abbasi', 'Arash Ghafouri', 'Ma...</td>\n",
       "      <td>http://arxiv.org/abs/2312.15713v1</td>\n",
       "      <td>http://arxiv.org/pdf/2312.15713v1</td>\n",
       "      <td>2023-12-25T12:48:55Z</td>\n",
       "      <td>2312.15713v1</td>\n",
       "      <td>2312.15713v1.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Cedille: A large autoregressive French languag...   \n",
       "1  A Precis of Language Models are not Models of ...   \n",
       "2  Integrating AI Planning with Natural Language ...   \n",
       "3  Multilingual Text Classification for Dravidian...   \n",
       "4  PersianLLaMA: Towards Building First Persian L...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Scaling up the size and training of autoregres...   \n",
       "1  Natural Language Processing is one of the lead...   \n",
       "2  Natural language processing (NLP) aims at inve...   \n",
       "3  As the fourth largest language family in the w...   \n",
       "4  Despite the widespread use of the Persian lang...   \n",
       "\n",
       "                                             authors  \\\n",
       "0               ['Martin Müller', 'Florian Laurent']   \n",
       "1                                    ['Csaba Veres']   \n",
       "2                ['Kebing Jin', 'Hankz Hankui Zhuo']   \n",
       "3  ['Xiaotian Lin', 'Nankai Lin', 'Kanoksak Watta...   \n",
       "4  ['Mohammad Amin Abbasi', 'Arash Ghafouri', 'Ma...   \n",
       "\n",
       "                                 url                           pdf_link  \\\n",
       "0  http://arxiv.org/abs/2202.03371v1  http://arxiv.org/pdf/2202.03371v1   \n",
       "1  http://arxiv.org/abs/2205.07634v1  http://arxiv.org/pdf/2205.07634v1   \n",
       "2  http://arxiv.org/abs/2202.07138v2  http://arxiv.org/pdf/2202.07138v2   \n",
       "3  http://arxiv.org/abs/2112.01705v1  http://arxiv.org/pdf/2112.01705v1   \n",
       "4  http://arxiv.org/abs/2312.15713v1  http://arxiv.org/pdf/2312.15713v1   \n",
       "\n",
       "              published      arxiv_id     pdf_file_name  \n",
       "0  2022-02-07T17:40:43Z  2202.03371v1  2202.03371v1.pdf  \n",
       "1  2022-05-16T12:50:58Z  2205.07634v1  2205.07634v1.pdf  \n",
       "2  2022-02-15T02:19:09Z  2202.07138v2  2202.07138v2.pdf  \n",
       "3  2021-12-03T04:26:49Z  2112.01705v1  2112.01705v1.pdf  \n",
       "4  2023-12-25T12:48:55Z  2312.15713v1  2312.15713v1.pdf  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_pdfs = pd.read_csv(DF_PDF_CSV_FILEPATH)\n",
    "df_with_pdfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and splitting into chunks: 2202.03371v1.pdf\n",
      "Loading and splitting into chunks: 2205.07634v1.pdf\n",
      "Loading and splitting into chunks: 2202.07138v2.pdf\n",
      "Loading and splitting into chunks: 2112.01705v1.pdf\n",
      "Loading and splitting into chunks: 2312.15713v1.pdf\n",
      "Loading and splitting into chunks: 2305.06530v1.pdf\n",
      "Loading and splitting into chunks: 2401.04155v1.pdf\n",
      "Loading and splitting into chunks: 2112.07055v2.pdf\n",
      "Loading and splitting into chunks: 2404.04748v1.pdf\n",
      "Loading and splitting into chunks: 2210.14473v1.pdf\n",
      "Loading and splitting into chunks: 2212.03419v1.pdf\n",
      "Loading and splitting into chunks: 2406.07259v1.pdf\n",
      "Loading and splitting into chunks: 1608.04434v1.pdf\n",
      "Loading and splitting into chunks: 2408.02237v1.pdf\n",
      "Loading and splitting into chunks: 2308.15118v1.pdf\n",
      "Loading and splitting into chunks: 2311.04329v2.pdf\n",
      "Loading and splitting into chunks: 2406.17873v1.pdf\n",
      "Loading and splitting into chunks: 2101.06949v1.pdf\n",
      "Loading and splitting into chunks: 2210.07041v1.pdf\n",
      "Loading and splitting into chunks: 2411.02280v1.pdf\n",
      "Loading and splitting into chunks: 2306.09339v1.pdf\n",
      "Loading and splitting into chunks: 2004.13645v1.pdf\n",
      "Loading and splitting into chunks: 2311.05741v2.pdf\n",
      "Loading and splitting into chunks: 2312.01090v2.pdf\n",
      "Loading and splitting into chunks: 2310.00637v1.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>url</th>\n",
       "      <th>chunk</th>\n",
       "      <th>pre_chunk_id</th>\n",
       "      <th>post_chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2202.03371v1#0</td>\n",
       "      <td>Cedille: A large autoregressive French languag...</td>\n",
       "      <td>Scaling up the size and training of autoregres...</td>\n",
       "      <td>['Martin Müller', 'Florian Laurent']</td>\n",
       "      <td>2202.03371v1</td>\n",
       "      <td>http://arxiv.org/abs/2202.03371v1</td>\n",
       "      <td>CEDILLE :\\nA LARGE AUTOREGRESSIVE LANGUAGE MOD...</td>\n",
       "      <td></td>\n",
       "      <td>2202.03371v1#1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2202.03371v1#1</td>\n",
       "      <td>Cedille: A large autoregressive French languag...</td>\n",
       "      <td>Scaling up the size and training of autoregres...</td>\n",
       "      <td>['Martin Müller', 'Florian Laurent']</td>\n",
       "      <td>2202.03371v1</td>\n",
       "      <td>http://arxiv.org/abs/2202.03371v1</td>\n",
       "      <td>auto-regressive language model, speciﬁcally tr...</td>\n",
       "      <td>2202.03371v1#0</td>\n",
       "      <td>2202.03371v1#2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2202.03371v1#2</td>\n",
       "      <td>Cedille: A large autoregressive French languag...</td>\n",
       "      <td>Scaling up the size and training of autoregres...</td>\n",
       "      <td>['Martin Müller', 'Florian Laurent']</td>\n",
       "      <td>2202.03371v1</td>\n",
       "      <td>http://arxiv.org/abs/2202.03371v1</td>\n",
       "      <td>Large autoregressive language models have draw...</td>\n",
       "      <td>2202.03371v1#1</td>\n",
       "      <td>2202.03371v1#3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2202.03371v1#3</td>\n",
       "      <td>Cedille: A large autoregressive French languag...</td>\n",
       "      <td>Scaling up the size and training of autoregres...</td>\n",
       "      <td>['Martin Müller', 'Florian Laurent']</td>\n",
       "      <td>2202.03371v1</td>\n",
       "      <td>http://arxiv.org/abs/2202.03371v1</td>\n",
       "      <td>Although large language models, such as GPT-3 ...</td>\n",
       "      <td>2202.03371v1#2</td>\n",
       "      <td>2202.03371v1#4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2202.03371v1#4</td>\n",
       "      <td>Cedille: A large autoregressive French languag...</td>\n",
       "      <td>Scaling up the size and training of autoregres...</td>\n",
       "      <td>['Martin Müller', 'Florian Laurent']</td>\n",
       "      <td>2202.03371v1</td>\n",
       "      <td>http://arxiv.org/abs/2202.03371v1</td>\n",
       "      <td>models [5].\\nMonolingual autoregressive langua...</td>\n",
       "      <td>2202.03371v1#3</td>\n",
       "      <td>2202.03371v1#5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                              title  \\\n",
       "0  2202.03371v1#0  Cedille: A large autoregressive French languag...   \n",
       "1  2202.03371v1#1  Cedille: A large autoregressive French languag...   \n",
       "2  2202.03371v1#2  Cedille: A large autoregressive French languag...   \n",
       "3  2202.03371v1#3  Cedille: A large autoregressive French languag...   \n",
       "4  2202.03371v1#4  Cedille: A large autoregressive French languag...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Scaling up the size and training of autoregres...   \n",
       "1  Scaling up the size and training of autoregres...   \n",
       "2  Scaling up the size and training of autoregres...   \n",
       "3  Scaling up the size and training of autoregres...   \n",
       "4  Scaling up the size and training of autoregres...   \n",
       "\n",
       "                                authors      arxiv_id  \\\n",
       "0  ['Martin Müller', 'Florian Laurent']  2202.03371v1   \n",
       "1  ['Martin Müller', 'Florian Laurent']  2202.03371v1   \n",
       "2  ['Martin Müller', 'Florian Laurent']  2202.03371v1   \n",
       "3  ['Martin Müller', 'Florian Laurent']  2202.03371v1   \n",
       "4  ['Martin Müller', 'Florian Laurent']  2202.03371v1   \n",
       "\n",
       "                                 url  \\\n",
       "0  http://arxiv.org/abs/2202.03371v1   \n",
       "1  http://arxiv.org/abs/2202.03371v1   \n",
       "2  http://arxiv.org/abs/2202.03371v1   \n",
       "3  http://arxiv.org/abs/2202.03371v1   \n",
       "4  http://arxiv.org/abs/2202.03371v1   \n",
       "\n",
       "                                               chunk    pre_chunk_id  \\\n",
       "0  CEDILLE :\\nA LARGE AUTOREGRESSIVE LANGUAGE MOD...                   \n",
       "1  auto-regressive language model, speciﬁcally tr...  2202.03371v1#0   \n",
       "2  Large autoregressive language models have draw...  2202.03371v1#1   \n",
       "3  Although large language models, such as GPT-3 ...  2202.03371v1#2   \n",
       "4  models [5].\\nMonolingual autoregressive langua...  2202.03371v1#3   \n",
       "\n",
       "    post_chunk_id  \n",
       "0  2202.03371v1#1  \n",
       "1  2202.03371v1#2  \n",
       "2  2202.03371v1#3  \n",
       "3  2202.03371v1#4  \n",
       "4  2202.03371v1#5  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_chunks = add_chunks_to_df(df_with_pdfs)\n",
    "df_with_chunks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pincone Vector Db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model_name, texts):\n",
    "    # Define the Hugging Face Embeddings\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "    embeddings_list = []\n",
    "    for text in texts:\n",
    "        embeddings_list.append(embeddings.embed_query(text))\n",
    "\n",
    "    return embeddings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02744012512266636, -0.011006052605807781, 0.042352523654699326, -0.042772505432367325, 0.016905877739191055, 0.02067454159259796, 0.019077520817518234, 0.05208282172679901, 0.01198798231780529, 0.010680303908884525, -0.004819100257009268, -0.045714251697063446, 0.018787158653140068, 0.04544045031070709, 0.021978164091706276, 0.012238230556249619, 0.028512557968497276, -0.014150147326290607, -0.0911283940076828, 0.006428318563848734, 0.08000028878450394, 0.023755745962262154, -0.028776006773114204, -0.059667229652404785, -0.006049215327948332, -0.0013380016898736358, -0.025655802339315414, 0.02398783527314663, 0.0003496247809380293, -0.17968158423900604, -0.024698453024029732, -0.028057819232344627, 0.058816201984882355, -0.0075118388049304485, 0.025728149339556694, -0.03086206130683422, -0.009181546047329903, 0.03781155124306679, -0.041793689131736755, 0.008646606467664242, 0.040567584335803986, -0.006288799457252026, 0.0003736849466804415, -0.023562859743833542, 0.009550483897328377, -0.02876909449696541, -0.015057433396577835, 0.019363662227988243, 0.0065833088010549545, -0.01976776123046875, -0.014201322570443153, -0.04411972686648369, -0.0038438024930655956, 0.006830241065472364, 0.032169897109270096, 0.06241781637072563, 0.05512905493378639, 0.027182094752788544, 0.026395125314593315, 0.0007585729472339153, 0.029297029599547386, 0.02159981243312359, -0.12845943868160248, 0.05513976886868477, 0.020595675334334373, -0.0007622258854098618, 0.004647486377507448, 0.014598398469388485, -0.009589710272848606, 0.004334624391049147, -0.02403104305267334, 0.00842350348830223, 0.018244797363877296, 0.04514111578464508, 0.00742089981213212, -0.010616600513458252, 0.015332779847085476, -0.03494581952691078, 0.00017034393385984004, -0.012556098401546478, -0.04354654997587204, 0.008626156486570835, 0.006155007053166628, -0.006374339107424021, -0.0318412184715271, -0.04276464879512787, -0.006143296603113413, 0.012070049531757832, -0.0178909320384264, 0.00010029364784713835, -0.01023145392537117, -0.025945225730538368, -0.021976124495267868, 0.004961039405316114, -0.06036156788468361, -0.004670910071581602, 0.0184465479105711, 0.01915718987584114, -0.047130782157182693, 0.5395793914794922, -0.05422089248895645, -0.0008760039927437901, 0.05765806883573532, -0.06239630654454231, 0.03983861207962036, 0.003900491865351796, -0.01812196895480156, -0.03223906084895134, -0.009310746565461159, 0.008195064030587673, 0.01770792342722416, -0.03357439488172531, 0.06154453009366989, -0.018131157383322716, 0.012228069826960564, -0.005966922268271446, 0.03129561245441437, 0.013539263047277927, 0.06831832975149155, -0.0054482086561620235, 0.00916234403848648, 0.00207599438726902, 0.0016155127668753266, -0.012158761732280254, 0.04883807152509689, -0.08541762828826904, 0.038618817925453186, 0.0803341343998909, 0.003305456368252635, 0.07077503204345703, 0.015589644201099873, 0.04051734134554863, -0.04010101780295372, 3.7106943636899814e-05, 0.010084616020321846, -0.014841887168586254, -0.01746208406984806, -0.0037773565854877234, 0.0327635295689106, -0.02850671485066414, -0.03326232358813286, -0.08974868804216385, -0.0202947948127985, -0.10682607442140579, -0.022494591772556305, 0.04140042886137962, -0.04631083458662033, 0.01653030514717102, -0.010166376829147339, 0.03869103640317917, -0.020462457090616226, 0.023842530325055122, -0.005559067707508802, -0.02782466448843479, 0.013902134262025356, 0.019599614664912224, 0.011537870392203331, 0.04940210282802582, -0.011837957426905632, 0.0037425856571644545, -0.012368080206215382, -0.03772784397006035, -0.046125493943691254, 0.010266026481986046, 0.004494591616094112, -0.12555833160877228, -0.006200460717082024, 0.00843664538115263, -0.0016555036418139935, -0.022474117577075958, 0.0077408840879797935, 0.015988068655133247, -0.060488756746053696, 0.04078996181488037, 0.0911831259727478, 0.04166947305202484, -0.012834482826292515, 0.020296460017561913, -0.018021125346422195, 0.025494083762168884, 0.04301640763878822, -0.036727845668792725, -0.025671588256955147, 0.016137316823005676, 0.006464486941695213, -0.0367591567337513, -0.018247565254569054, -0.0017948489403352141, 0.035024493932724, 0.0660402923822403, -0.025897108018398285, -0.005063286982476711, -0.01656707003712654, -0.03316819295287132, -0.042845718562603, -0.022824589163064957, 0.027084844186902046, -0.02652783691883087, 0.009845485910773277, -0.021283479407429695, 0.10037299245595932, -0.0023739205207675695, -0.0007071321597322822, 0.04488680884242058, 0.010318910703063011, 0.0160164013504982, 0.03922778740525246, -0.0022171998862177134, 0.021385004743933678, 0.013771635480225086, -0.02282632514834404, -0.0029640747234225273, 0.07713314145803452, 0.02249808795750141, 0.01394102443009615, -0.019560998305678368, -0.021063460037112236, 0.026916896924376488, -0.008859803900122643, 0.020788216963410378, 0.011852461844682693, -0.013783522881567478, -0.03779277577996254, -0.24854788184165955, 0.023000327870249748, -0.011560413055121899, -0.017517253756523132, 0.023536259308457375, -0.010391498915851116, 0.05602717772126198, -0.028510788455605507, 0.07577860355377197, 0.009737220592796803, 0.06824222952127457, -0.05768895894289017, -0.00793340802192688, -0.021663984283804893, -0.010177485644817352, 0.023613298311829567, -0.0017022459069266915, 0.010099413804709911, -0.012801863253116608, -0.017031354829669, -0.01712062768638134, 0.01287108100950718, 0.030502300709486008, -0.031488023698329926, 0.023583613336086273, -0.04225214198231697, 0.16950707137584686, 0.10203234851360321, 0.028749454766511917, 0.028871964663267136, 0.019206104800105095, 0.006235321052372456, -0.02901812456548214, -0.11998782306909561, 0.022007310763001442, 0.05354632809758186, -0.012652230449020863, -0.056570034474134445, -0.06003813073039055, -0.007279659621417522, -0.013552403077483177, 0.04749586433172226, -0.014153538271784782, -0.03464414179325104, -0.015292408876121044, -0.05333562195301056, -0.055960264056921005, -0.0059874835424125195, -0.050138793885707855, 0.013628979213535786, 0.025065338239073753, 0.005719078239053488, 0.020843926817178726, 0.05217809975147247, -0.01320180669426918, -0.019299525767564774, -0.046837009489536285, -0.006942383479326963, -0.008214658126235008, 0.03387458622455597, -0.018654614686965942, -0.01253997441381216, -0.007951222360134125, -0.015491214580833912, 0.011025271378457546, 0.018433168530464172, -0.05183440074324608, -0.02943936362862587, 0.05862352252006531, -0.03306480124592781, -0.030920468270778656, -0.018611250445246696, 0.0031230913009494543, -0.022459067404270172, 0.037934739142656326, 0.019245570525527, -0.011820427142083645, -0.019595036283135414, -0.0341324508190155, -0.025993769988417625, 0.02435263991355896, -0.026184124872088432, 0.03830305486917496, 0.019929461181163788, 0.0276683047413826, 0.03704420104622841, 0.04884801059961319, 0.00891125574707985, 0.0174812451004982, -0.02842124179005623, -0.009188367053866386, 0.02063853107392788, -0.011416226625442505, -0.0638776496052742, 0.00949773658066988, -0.02238868735730648, -0.3244476914405823, 0.036873962730169296, 0.010371520183980465, 0.028651254251599312, -0.027413880452513695, 0.028595270588994026, 0.030343951657414436, 0.01063829567283392, -0.04602629318833351, 0.020470798015594482, -0.05367221683263779, 0.028294017538428307, -0.0003836577816400677, -0.02756413072347641, 0.009715390391647816, 0.01673246920108795, 0.03039160929620266, -0.03294999524950981, 0.011250856332480907, -0.01865546964108944, -0.013508488424122334, 0.03291939198970795, 0.22265766561031342, -0.05595724284648895, 0.05713729187846184, 0.05015258118510246, -0.004127430263906717, 0.020044827833771706, 0.00971096009016037, -0.005269542336463928, -0.020940249785780907, -0.001985980197787285, 0.008768167346715927, -0.03083186037838459, 0.034826651215553284, 0.002862701890990138, -0.038040440529584885, 0.011947860941290855, 0.000963930506259203, -0.031226348131895065, -0.05080034211277962, 0.030527722090482712, -0.03175230324268341, 0.020201552659273148, -0.0021762230899184942, -0.05109473690390587, -0.013496523723006248, -0.03472423180937767, 0.04054123908281326, 0.017081327736377716, -0.029686955735087395, -0.024664267897605896, 0.00045398337533697486, 0.0008931368356570601, 0.0021564785856753588, 0.0064324550330638885, -0.023267487064003944, 0.006178985815495253, 0.012919418513774872, -0.030366359278559685, 0.015994492918252945, -0.04309102147817612, 0.038834281265735626, 0.013747266493737698, 0.01997441053390503], [-0.01879553310573101, -0.018542490899562836, 0.042556509375572205, -0.007225449662655592, 0.043921444565057755, 0.025988638401031494, 0.02905598096549511, 0.0397312194108963, 0.02874826081097126, 0.0004056951147504151, 0.0038871674332767725, -0.04551570490002632, 0.05004117265343666, 0.044011615216732025, 0.008539860136806965, -0.020252589136362076, -0.021170467138290405, 0.04154149070382118, -0.08163884282112122, -0.0004839180037379265, 0.047532640397548676, 0.010749194771051407, -0.025952059775590897, -0.031342968344688416, 0.00579735916107893, 0.037138957530260086, -0.05066009610891342, -0.007614610716700554, -0.03246094286441803, -0.1617499589920044, -0.007832173258066177, -0.055842798203229904, -0.014647469855844975, 0.015308534726500511, -0.015142804011702538, -0.023466715589165688, 0.003545108251273632, -0.015936212614178658, -0.0692460685968399, 0.05948301777243614, 0.045848947018384933, 0.01737930066883564, 0.016277816146612167, -0.03830723837018013, -0.026027891784906387, -0.025564448907971382, -0.0313149094581604, -0.02158482000231743, 0.04111316800117493, -0.027073336765170097, 0.02716502733528614, -0.024686872959136963, -0.029970567673444748, 0.001452230615541339, 0.014680096879601479, 0.029093779623508453, 0.03580237552523613, 0.03135709464550018, 0.04537494480609894, -0.02183230221271515, 0.027158472687005997, 0.003954277373850346, -0.16732414066791534, 0.07142824679613113, 0.01867082715034485, 0.00522597087547183, 0.025434495881199837, -0.0031637693755328655, 0.0031273725908249617, 0.07438302785158157, -0.06223420798778534, -0.0012954837875440717, 0.033109407871961594, 0.05767763778567314, 0.013920632191002369, -0.007470731623470783, -0.011373947374522686, -0.030502893030643463, 0.011649107560515404, -0.009997328743338585, 0.002120592165738344, -0.046237748116254807, -0.007570894900709391, 0.027654504403471947, -0.026706473901867867, -0.023699043318629265, -0.034000277519226074, 0.021081017330288887, 0.003207719884812832, -0.02703057788312435, -0.050599660724401474, -0.019186172634363174, 0.06693530082702637, 0.03413643687963486, -0.04812188819050789, -0.011943195946514606, 0.039675891399383545, 0.010800535790622234, -0.0425383560359478, 0.5111815333366394, -0.07786624878644943, 0.018026873469352722, 0.013561069034039974, -0.08143473416566849, 0.047843050211668015, -0.011138559319078922, -0.05099034681916237, -0.0004483788216020912, -0.00894817803055048, 0.008106219582259655, -0.001996647333726287, -0.03250847011804581, 0.08157725632190704, 0.0077560883946716785, 0.010711968876421452, -0.011441008187830448, 0.023782581090927124, 0.04296508803963661, 0.013143696822226048, 0.001825380022637546, -0.06045681983232498, 0.01059804018586874, 0.014785578474402428, 0.022032013162970543, 0.0703858733177185, -0.07136011868715286, 0.06198569014668465, 0.1109451875090599, 0.011602938175201416, 0.02968091331422329, 0.02905530296266079, -0.010226150043308735, -0.025013748556375504, 0.003912562038749456, 0.027197156101465225, 0.007089064456522465, 0.00930769182741642, 0.021754654124379158, 0.016276489943265915, -0.04482557997107506, 0.01013838779181242, -0.0970374345779419, -0.043918121606111526, -0.0908530056476593, 0.023298680782318115, 0.03709310293197632, -0.03114635869860649, -0.007623896934092045, 0.0042569199576973915, 0.05550932511687279, 0.014518693089485168, 0.04234873130917549, -0.02141793817281723, 0.0224535521119833, 0.020592154935002327, 0.04461447522044182, 0.027832407504320145, 0.03395075723528862, -0.024166366085410118, 0.010955885984003544, -0.03993510082364082, -0.015554715879261494, -0.032274577766656876, 0.014987376518547535, -0.024861717596650124, -0.05973592773079872, -0.04458692669868469, -0.006173134781420231, -0.015841523185372353, -0.007887053303420544, -0.014444002881646156, -0.02489248290657997, -0.032742518931627274, -0.00861000083386898, 0.12448278814554214, 0.02184887044131756, -0.0006037998246029019, 0.04116302356123924, -0.016517141833901405, 0.03467237204313278, -0.031007610261440277, -0.028649915009737015, -0.009141282178461552, 0.003985070623457432, 0.013447846285998821, -0.009018330834805965, -0.005892216227948666, -0.017718305811285973, 0.0661032497882843, 0.017675071954727173, 0.0007351906388066709, 0.007936066016554832, -0.018085764721035957, -0.021729610860347748, -0.03097681514918804, -0.0015465812757611275, -0.035439059138298035, -0.027465470135211945, 0.037348322570323944, -0.03116530366241932, 0.0487186573445797, -0.028893502429127693, -0.030117318034172058, -0.007904775440692902, 0.027951659634709358, 0.0536067970097065, 0.055787816643714905, 0.00019676666124723852, 0.03962259739637375, 0.04286566749215126, -0.004565306007862091, -0.03151954710483551, 0.09092622250318527, -0.004398208111524582, 0.023055829107761383, -0.014213371090590954, 0.0005412409664131701, -0.0099751316010952, -0.027450168505311012, -0.0032564117573201656, 0.0017023268155753613, -0.05791918560862541, -0.053765639662742615, -0.2546144127845764, 0.04385729879140854, -0.027329575270414352, -0.06319878995418549, 0.03463441878557205, -0.042832449078559875, 0.02516799606382847, -0.053915783762931824, 0.059697460383176804, 0.040920332074165344, 0.0495816133916378, -0.035500068217515945, 0.0036135774571448565, 0.02684939093887806, 0.016584321856498718, 0.019283166155219078, -0.007637861184775829, -0.0014156150864437222, -0.03542282059788704, -0.013940073549747467, 0.025166617706418037, 0.005273228976875544, -0.019193023443222046, -0.07104847580194473, 0.037689004093408585, -0.0334724523127079, 0.18331611156463623, 0.07912136614322662, 0.0356811061501503, 0.006440793629735708, 0.023847831413149834, 0.059383854269981384, 0.0011845071567222476, -0.12537473440170288, 0.006520920433104038, 0.043333750218153, -0.003937923349440098, -0.06702105700969696, -0.05549924820661545, -0.04132626950740814, -0.032988615334033966, 0.039138928055763245, -0.02257426641881466, -0.090354323387146, 0.013673480600118637, -0.029193740338087082, -0.02479126863181591, 0.010990840382874012, -0.014046333730220795, -0.03367308899760246, 0.0529235377907753, -0.02651895023882389, 0.0208449624478817, 0.02367260307073593, -0.01767752878367901, -0.03589775413274765, -0.03068636544048786, 0.010127687826752663, -0.03222769498825073, 0.007275554817169905, -0.03170210123062134, 0.003004347672685981, -0.01932569406926632, 0.01188832800835371, -0.03291705250740051, 0.026119695976376534, -0.012259401381015778, -0.013110462576150894, 0.06540980935096741, -0.035436782985925674, -0.05345676466822624, 0.00930529460310936, 0.021575726568698883, -0.05301135405898094, 0.0429072231054306, 0.017777306959033012, 0.01798117347061634, 0.03454473242163658, -0.07788237929344177, -0.027163028717041016, 0.03953799232840538, -0.03561137244105339, 0.05930443853139877, 0.04961470514535904, -0.0032739073503762484, 0.016970572993159294, 0.04657511040568352, 0.008313922211527824, 0.0005922616692259908, -0.00353457173332572, -0.007600345648825169, 0.03803504258394241, -0.022874612361192703, -0.023501839488744736, 0.023420775309205055, -0.048646897077560425, -0.25936195254325867, 0.012786016799509525, 0.010315836407244205, 0.05330879986286163, -0.02511705458164215, 0.057788193225860596, 0.007049330975860357, 0.032797496765851974, -0.048098817467689514, 0.029676470905542374, -0.020219968631863594, 0.03437287360429764, 0.03834254667162895, -0.006160398479551077, 0.044069383293390274, 0.019007861614227295, 0.03215906396508217, -0.0021974004339426756, 0.029772914946079254, 0.035547610372304916, 0.008665584959089756, -0.005768931470811367, 0.16801758110523224, -0.02052527479827404, 0.055038921535015106, 0.056685540825128555, -0.02332836203277111, 0.02355380542576313, -0.007463668938726187, -0.02049710974097252, -0.03667841851711273, 0.001425440306775272, 0.0026443025562912226, -0.0747322365641594, 0.0026041101664304733, -0.011693385429680347, -0.014845401048660278, 0.045797038823366165, 0.017770038917660713, -0.02363906241953373, -0.040839556604623795, 0.02840108424425125, 0.031362637877464294, -0.022134505212306976, 0.03955879807472229, -0.053890328854322433, -0.07060597836971283, -0.03570428118109703, 0.04888007417321205, 0.030318202450871468, -0.04223647713661194, 0.006823086645454168, -0.028468633070588112, 0.031143270432949066, -0.02941427007317543, 0.023188183084130287, -0.056522708386182785, -0.014188944362103939, -0.0013746890472248197, -0.05573234334588051, 0.013447264209389687, -0.04439311847090721, -0.0059469519183039665, 0.01137896440923214, -0.0059462604112923145]]\n",
      "384\n"
     ]
    }
   ],
   "source": [
    "model_name = EMBEDDING_MODEL_NAME\n",
    "input_text = [\"Hello World!\", \"Goodbye World!\"]\n",
    "\n",
    "embeddings = get_embeddings(model_name, input_text)\n",
    "\n",
    "print(len(embeddings[0]))\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PinconeVectorDb:\n",
    "    def __init__(self, \n",
    "                 cloud: str='aws', \n",
    "                 region: str='us-east-1'):\n",
    "        \"\"\"\n",
    "        Initialize the PinconeVectorDb class.\n",
    "        Args:\n",
    "            cloud (str): The cloud provider for Pinecone. Default is 'aws'.\n",
    "            region (str): The AWS region for Pinecone. Default is 'us-east-1'.\n",
    "        \"\"\"\n",
    "        # Check if 'PINECONE_API_KEY' is set; prompt if not\n",
    "        self.pc_api_key = os.getenv('PINECONE_API_KEY') or getpass('Pinecone API key: ')\n",
    "        self.pc, self.spec = self.initialize_pinecone_client(cloud=cloud, \n",
    "                                                             region=region)\n",
    "    \n",
    "    def initialize_pinecone_client(self, cloud: str, region: str):\n",
    "        \"\"\"\n",
    "        Initialize the Pinecone client and return it.\n",
    "        Args:\n",
    "            cloud (str): The cloud provider for Pinecone. \n",
    "            region (str): The AWS region for Pinecone.\n",
    "        Returns:\n",
    "            Pinecone client and serverless specification objects.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize the Pinecone client\n",
    "        pc = Pinecone(api_key=self.pc_api_key)\n",
    "        # Define the serverless specification for Pinecone (AWS region 'us-east-1')\n",
    "        spec = ServerlessSpec(\n",
    "            cloud=cloud, \n",
    "            region=region\n",
    "        )\n",
    "\n",
    "        return pc, spec\n",
    "    \n",
    "    def create_pinecone_index(self,\n",
    "                                index_name: str=INDEX_NAME, \n",
    "                                EMBEDDING_DIMS: int=EMBEDDING_DIMS, \n",
    "                                metric: str='cosine') -> Index:\n",
    "        \"\"\"\n",
    "        Creates a Pinecone index with the given name and dimensions.\n",
    "        Args:\n",
    "            index_name (str): The name of the index. Default is INDEX_NAME.\n",
    "            EMBEDDING_DIMS (int): The dimensionality of the embeddings. Default is EMBEDDING_DIMS.\n",
    "            metric (str): The metric used for similarity. Default is 'cosine'.\n",
    "        Returns:\n",
    "            Pinecone index object.\n",
    "        \"\"\"\n",
    "\n",
    "        # Check if the index exists; create it if it doesn't\n",
    "        if index_name not in self.pc.list_indexes().names():\n",
    "            self.pc.create_index(\n",
    "                index_name,\n",
    "                dimension=EMBEDDING_DIMS,  # Embedding dimension\n",
    "                metric=metric,\n",
    "                spec=self.spec  # Cloud provider and region specification\n",
    "            )\n",
    "\n",
    "            # Wait until the index is fully initialized\n",
    "            while not self.pc.describe_index(index_name).status['ready']:\n",
    "                time.sleep(1)\n",
    "\n",
    "        # Connect to the index\n",
    "        self.index = self.pc.Index(index_name)\n",
    "\n",
    "        # Add a short delay before checking the stats\n",
    "        time.sleep(1)\n",
    "\n",
    "        # View the index statistics\n",
    "        print(f\"Index Stats:\\n{self.index.describe_index_stats()}\")\n",
    "    \n",
    "    def get_embeddings(self,\n",
    "                       texts: list[str],\n",
    "                       model_name: str=EMBEDDING_MODEL_NAME):\n",
    "        # Define the Hugging Face Embeddings\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "        embeddings_list = []\n",
    "        for text in texts:\n",
    "            embeddings_list.append(embeddings.embed_query(text))\n",
    "\n",
    "        return embeddings_list\n",
    "    \n",
    "    def add_embeddings_to_index(self, \n",
    "                                data: pd.DataFrame, \n",
    "                                batch_size: int=BATCH_SIZE,):\n",
    "\n",
    "        # data = expanded_df\n",
    "        # batch_size = 64  # Set batch size\n",
    "\n",
    "        # Loop through the data in batches, using tqdm for a progress bar\n",
    "        for i in tqdm(range(0, len(data), batch_size)):\n",
    "            i_end = min(len(data), i + batch_size)  # Define batch endpoint\n",
    "            batch = data[i:i_end].to_dict(orient='records')  # Slice data into a batch\n",
    "\n",
    "            # Extract metadata for each chunk in the batch\n",
    "            metadata = [{\n",
    "                'arxiv_id': r['arxiv_id'],\n",
    "                'title': r['title'],\n",
    "                'chunk': r['chunk'],\n",
    "            } for r in batch]\n",
    "            \n",
    "            # Generate unique IDs for each chunk\n",
    "            ids = [r['id'] for r in batch]\n",
    "            \n",
    "            # Extract the chunk content\n",
    "            chunks = [r['chunk'] for r in batch]\n",
    "            \n",
    "            # Convert chunks into embeddings\n",
    "            embeds = self.get_embeddings(chunks)\n",
    "            \n",
    "            # Upload embeddings, IDs, and metadata to Pinecone\n",
    "            self.index.upsert(vectors=zip(ids, embeds, metadata))\n",
    "            \n",
    "            # View the index statistics\n",
    "            print(f\"Index Stats:\\n{self.index.describe_index_stats()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Stats:\n",
      "{'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [15:10<00:00, 13.01s/it]\n"
     ]
    }
   ],
   "source": [
    "pc = PinconeVectorDb()\n",
    "pc.create_pinecone_index()\n",
    "pc.add_embeddings_to_index(data=df_with_chunks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
